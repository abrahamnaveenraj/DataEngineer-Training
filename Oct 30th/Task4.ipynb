{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiUL64LvtAJC",
        "outputId": "634c36b5-d87e-4f20-83d7-e28aa5114618"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import sum as spark_sum, desc\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Retail_ETL_Simulation\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "qiv6mA3ZtLhF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales = spark.read.csv(\"sales_cleaned.csv\", header=True, inferSchema=True)\n",
        "inventory = spark.read.csv(\"inventory_cleaned.csv\", header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "sPK6gNnJtNYR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_summary = sales.groupBy(\"product_id\").agg(\n",
        "    spark_sum(\"quantity\").alias(\"units_sold\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "uT3i0rVBtQsp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = sales_summary.join(inventory, \"product_id\")\n",
        "final_data = final_data.withColumn(\n",
        "    \"remaining_stock\",\n",
        "    final_data[\"stock\"] - final_data[\"units_sold\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "GbbT89SttTVK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.write.mode(\"overwrite\").csv(\"retail_etl_output\", header=True)\n",
        "\n",
        "final_data.createOrReplaceTempView(\"retail_table\")\n"
      ],
      "metadata": {
        "id": "FQEyVqe5tWYO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.createOrReplaceTempView(\"retail_table\")\n"
      ],
      "metadata": {
        "id": "OrDKmmJQtdlc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_products = spark.sql(\"\"\"\n",
        "    SELECT product_id, units_sold\n",
        "    FROM retail_table\n",
        "    ORDER BY units_sold DESC\n",
        "    LIMIT 5\n",
        "\"\"\")\n",
        "\n",
        "top_products.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atwPLFzstgBM",
        "outputId": "f2b8b2de-fc86-4904-961f-9c4b01d58f53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|product_id|units_sold|\n",
            "+----------+----------+\n",
            "|       101|         8|\n",
            "|       104|         6|\n",
            "|       103|         4|\n",
            "|       102|         3|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}